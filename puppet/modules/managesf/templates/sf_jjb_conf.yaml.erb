# Default configurations
- defaults:
    name: global
    description: |
      <p>Job is managed by Jenkins Job Builder</a>.</p>

    project-type: freestyle
    wrappers:
      - ansicolor:
          colormap: gnome-terminal
    concurrent: true

- builder:
    name: prepare-workspace
    builders:
      - shell: |
          # If this is called in a periodic job, these will not be set
          echo "Use default for ZUUL_BRANCH and ZUUL_REF if needed"
          export ZUUL_BRANCH=${ZUUL_BRANCH:-master}
          export ZUUL_REF=${ZUUL_REF:-None}
          # In the post pipeline ZUUL_REF is master but does not behave as we want
          # So fall back on None
          [ "$ZUUL_REF" = "master" ] && ZUUL_REF=None
          echo "Clean workspace"
          rm -Rf ./*
          echo "Clone $ZUUL_PROJECT"
          zuul-cloner http://<%= @fqdn %>/r $ZUUL_PROJECT

- builder:
    name: zuul-swift-upload
    builders:
      - shell: |
          # Publish artifacts on a Swift server
          /usr/local/bin/zuul_swift_upload.py --name artifacts --delete-after 0 artifacts

- builder:
    name: rdo-prepare
    builders:
      - shell: |
          sudo packstack --allinone --os-swift-install=y --os-ceilometer-install=n --nagios-install=n \
                --provision-demo=n --keystone-admin-passwd=sf4ever --os-heat-install=y --cinder-volumes-size=50G

          export OS_USERNAME=admin
          export OS_PASSWORD=sf4ever
          export OS_AUTH_URL=http://localhost:5000/v2.0
          export OS_TENANT_NAME=admin
          export OS_REGION_NAME=RegionOne

          echo "[+] Prepare external network provider"
          sudo openstack-config --set /etc/neutron/plugins/openvswitch/ovs_neutron_plugin.ini ovs bridge_mappings extnet:br-ex
          sudo openstack-config --set /etc/neutron/plugin.ini ml2 type_drivers vxlan,flat,vlan
          sudo service neutron-openvswitch-agent restart
          sudo service neutron-server restart

          echo "[+] Allow external access from vm"
          gw=$('ip' 'route' 'get' '8.8.8.8' | awk '{ print $5 }' | tr '\n' ' ' )
          sudo iptables -I POSTROUTING -t nat -s 192.168.42.1/24 -o $gw -j MASQUERADE
          sudo iptables -I FORWARD -i br-ex -o $gw -j ACCEPT
          sudo iptables -I FORWARD -o br-ex -i $gw -j ACCEPT

          echo "[+] Fix nova compute virt_type"
          sudo openstack-config --set /etc/nova/nova.conf libvirt virt_type kvm
          sudo openstack-config --set /etc/nova/nova.conf libvirt cpu_mode host-passthrough
          sudo systemctl restart openstack-nova-compute

          echo "[+] Create network"
          neutron net-create external_network --provider:network_type flat --provider:physical_network extnet --router:external > /dev/null
          neutron subnet-create --name public_subnet --enable_dhcp=False \
                --allocation-pool=start=192.168.42.10,end=192.168.42.200 \
                --gateway=192.168.42.1 external_network 192.168.42.0/24 > /dev/null
          neutron router-create external_gw > /dev/null
          neutron router-gateway-set external_gw external_network > /dev/null
          sudo ip a add 192.168.42.1/24 dev br-ex

          echo "[+] Install cirros"
          wget http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img &> /dev/null
          glance image-create --name=cirros --is-public=true --container-format=bare --disk-format=qcow2 < cirros-0.3.4-x86_64-disk.img > /dev/null

          echo "[+] Create 3 tenants"
          (for tenantname in sfmain sfnodepool sfswift; do
            openstack project create $tenantname
            openstack user create --project $tenantname --password sf4ever $tenantname
            openstack role add --project $tenantname --user $tenantname heat_stack_owner
          done) > /dev/null
          [ -f ~/.ssh/id_rsa ] || ssh-keygen -N '' -f ~/.ssh/id_rsa

          echo "[+] Customize tenants"
          (for tenantname in admin sfmain sfnodepool sfswift; do
            export OS_USERNAME=$tenantname
            export OS_TENANT_NAME=$tenantname

            echo "[+] Create network"
            neutron net-create ${tenantname}_network
            neutron subnet-create --name ${tenantname}_subnet --enable_dhcp=True \
                    --allocation-pool=start=192.168.201.10,end=192.168.201.200   \
                    --gateway 192.168.201.1 ${tenantname}_network 192.168.201.0/24
            neutron router-create ${tenantname}_gw
            neutron router-gateway-set ${tenantname}_gw external_network
            neutron router-interface-add ${tenantname}_gw ${tenantname}_subnet

            echo "[+] Allow ping and ssh"
            neutron security-group-rule-create --direction ingress --protocol ICMP default
            neutron security-group-rule-create --direction ingress --protocol TCP --port-range-min 22 --port-range-max 22 default

            echo "[+] Create Keypairs"
            nova keypair-add --pub-key ~/.ssh/id_rsa.pub id_rsa
          done) > /dev/null

- builder:
    name: rdo-check
    builders:
      - shell: |
          export OS_PASSWORD=sf4ever
          export OS_AUTH_URL=http://localhost:5000/v2.0
          export OS_REGION_NAME=RegionOne
          export OS_USERNAME=sfmain
          export OS_TENANT_NAME=sfmain
          echo "[+] Starting cirros"
          NET_ID=$(neutron net-list | grep $OS_TENANT_NAME | awk '{ print $2 }')
          nova boot --flavor m1.tiny --image cirros --key-name id_rsa --nic net-id=${NET_ID} watchdog
          sleep 5
          FLOATING=$(neutron floatingip-create external_network | grep floating_ip_address | awk '{ print $4 }')
          nova add-floating-ip watchdog ${FLOATING}
          ping -c 1 -w 5 ${FLOATING}


- publisher:
    name: zuul-swift-upload
    publishers:
      - postbuildscript:
          builders:
            - zuul-swift-upload
          script-only-if-succeeded: False
          script-only-if-failed: False

## Useful job template
- job-template:
    name: '{name}-unit-tests'
    defaults: global
    builders:
      - prepare-workspace
      - shell: cd $ZUUL_PROJECT && ./run_tests.sh
    triggers:
      - zuul
    node: '{node}'

- job-template:
    name: '{name}-functional-tests'
    defaults: global
    builders:
      - prepare-workspace
      - shell: cd $ZUUL_PROJECT && ./run_functional-tests.sh
    triggers:
      - zuul
    node: '{node}'

- job-template:
    name: '{name}-openstack-functional-tests'
    defaults: global
    builders:
      - prepare-workspace
      - rdo-prepare
      - shell: |
          export OS_PASSWORD=sf4ever
          export OS_AUTH_URL=http://localhost:5000/v2.0
          export OS_REGION_NAME=RegionOne
          export OS_USERNAME=sfmain
          export OS_TENANT_NAME=sfmain
          cd $ZUUL_PROJECT && ./run_functional-tests.sh
    triggers:
      - zuul
    node: '{node}'

- job-template:
    name: '{name}-publish-docs'
    defaults: global
    builders:
      - prepare-workspace
      - shell: cd $ZUUL_PROJECT && ./publish_docs.sh
    triggers:
      - zuul
    node: '{node}'

- job-template:
    name: '{name}-upload-to-pypi'
    defaults: global
    builders:
      - prepare-workspace
      - shell: |
          cp $PYPIRC ~/.pypirc
          cd $ZUUL_PROJECT
          python setup.py register -r pypi
          python setup.py sdist upload -r pypi
    wrappers:
      - credentials-binding:
          - file:
              credential-id: '{pypirc}'
              variable: PYPIRC
    triggers:
      - zuul
    node: '{node}'

# Config repository associated jobs
- job:
    name: 'config-check'
    defaults: global
    builders:
      - shell: |
          set -e
          rm -Rf config build
          zuul-cloner http://<%= @fqdn %>/r config
          # Prepare a default configuration for zuul and nodepool
          mkdir -p build/nodepool build/zuul
          (
            echo "[zuul]"
            echo
            echo "[connection gerrit]"
            echo "driver=gerrit"
            echo "server=localhost"
            echo "user=jenkins"
            echo ""
            echo "[connection smtp]"
            echo "driver=smtp"
            echo "server=localhost"
          ) > build/zuul/zuul.conf
          (
            echo "script-dir: /etc/nodepool/scripts"
            echo "images-dir: /opt/nodepool"
            echo "gearman-servers:"
            echo "  - host: 127.0.0.1"
            echo "targets:"
            echo "  - name: default"
            echo "providers:"
            echo "  - name: default"
            for provider in $(awk '/provider: / { print $NF }' config/nodepool/images.yaml); do
                echo "  - name: ${provider}"
            done
          ) > build/nodepool/nodepool.yaml
          cd config
          echo "[+] Checking jobs"
          # JJB needs access to jenkins to test (validate) jobs
          sudo jenkins-jobs test jobs/ -o ../build/
          echo "[+] Checking zuul"
          /usr/local/bin/yaml-merger.py zuul | tee ../build/zuul/layout.yaml
          cp zuul/*.py ../build/zuul/ || true
          zuul-server -c ../build/zuul/zuul.conf -l ../build/zuul/layout.yaml -t
          echo "[+] Checking nodepool"
          cp nodepool/*.yaml ../build/nodepool/
          WORKDIR=../build/nodepool/ /usr/local/bin/sf-nodepool-conf-merger.py merged.yaml
          nodepool -c ../build/nodepool/merged.yaml config-validate
          echo "[+] Checking gerrit replication"
          git config -f gerrit/replication.config -l > /dev/null
    triggers:
      - zuul
    node: master

- job:
    name: 'config-update'
    defaults: global
    builders:
      - shell: |
          echo "Updating configuration using $ZUUL_COMMIT"
          ssh root@managesf.<%= @fqdn %> /usr/local/bin/sf-config-update.sh
    triggers:
      - zuul
    node: master
